{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd907e48-5c8e-4da6-bf98-c0b2b4c1da25",
   "metadata": {},
   "source": [
    "# 1. 데이터 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cb781e-9a07-4fbf-9175-e4d1405f0e07",
   "metadata": {},
   "source": [
    "## 1.1. Tensor Data 정의\n",
    "* 파이토치 기본 데이터 타입은 Tensor이므로 모든 데이터는 먼저 텐서로 생성시켜야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab7be342-3196-414d-b344-6f6898590a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x_train=torch.Tensor([1,2,3,4,5,6]).view(6,1)\n",
    "y_train=torch.Tensor([3,4,5,6,7,8]).view(6,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7436eba5-c38d-41eb-afae-3a25c781dd76",
   "metadata": {},
   "source": [
    "## 1.2. DataSet/DataLoader 데이터 정의\n",
    "* 파이토치에서는 데이터를 좀 더 쉽게 다룰 수 있도록 TensorDataset과 DataLoader를 제공함.\n",
    "* 이를 사용하면 미니배치 학습 데이터 셔플(shuffle), 멀티 프로세싱 등을 간단하게 수정할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad5b22e7-5aeb-46d4-a56c-7ff34b96a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "x_train=torch.Tensor([1,2,3,4,5,6]).view(6,1)\n",
    "y_train=torch.Tensor([3,4,5,6,7,8]).view(6,1)\n",
    "\n",
    "dataset=TensorDataset(x_train,y_train) #텐서 데이터 생성\n",
    "\n",
    "dataloader=DataLoader(dataset, batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cfeb6d-6050-49f1-9781-181ac533387b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae891eb5-20d0-4ded-804a-ac7cd7b0983d",
   "metadata": {},
   "source": [
    "# 2.신경망 모델 구축\n",
    "* Pytorch에서 신경망 모델은 nn.Module을 상속받는 클래스를 생성하여 정의하는 것이 일반적임\n",
    "* 클래스 __init__함수에서 신경말 모델을 구성하는 다양항 계층 등을 정의하고\n",
    "* forward함수에서 신경망에 데이터를 어떻게 전달할지, 즉 포워드를 수행하고 결과값을 리턴함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa9ac05-c251-4800-a723-7bdbdf21425d",
   "metadata": {},
   "source": [
    "## 2.1 모델 클래스 정의 (Layers+forward정의)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "957af4ed-2bd9-4f42-90a0-c687c02b2968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class MyNeuralNetwork(nn.Module):\n",
    "\n",
    "    #신경망 모델을 구성하는 계층 정의\n",
    "    #입력데이터 1개 출력 데이터 1개\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten=nn.Flatten()\n",
    "        self.linear_relu_stack= nn.Sequential(\n",
    "           nn.Linear(1,1)\n",
    "        )\n",
    "\n",
    "    # 피드포워드를 수행하고 결과값을 리턴함\n",
    "    def forward(self,x):\n",
    "        x=self.flatten(x)\n",
    "        logits=self.linear_relu_stack(x)\n",
    "\n",
    "        return logits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca4044f-02f4-48c4-8376-36420469f12e",
   "metadata": {},
   "source": [
    "## 2.2 피드포워드/손실함수/모델 파라미터 최적화\n",
    "* 모델을 학습하려면 피드 포워드 계산 값과 정답의 차이인 오차(loss)를 계산하는 손실함수(loss function)와 옵티마이저(optimizer)가 필요함\n",
    "* 각 학습 단계에서 모델은 학습 데이터셋에 대한 예측을 수행하고, 오차(loss)를 역전파하여 모델의 파라미터를 최적화 시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24353183-a403-43f7-8b9a-ad0049eddee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "\n",
    "model=MyNeuralNetwork()\n",
    "\n",
    "# 손실함수 정의\n",
    "#일반적인 회귀regression 데이터에서는 nn.MSELoss()를,\n",
    "#분류 classifiacion 데이터에서는 nn.CrossEntropyLoss()를 사용\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "\n",
    "# 옵티마이저 정의\n",
    "# 옵티마이저에도 확률적 경사하강법 이외에도, ADAM, FMSProp 등의 다양한 옵티마이저가 있음\n",
    "\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c8132d1-a1f5-4535-b59c-902f8c7f99f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch= 0 current loss= 32.52552795410156\n",
      "epoch= 100 current loss= 0.5413830280303955\n",
      "epoch= 200 current loss= 0.2605785131454468\n",
      "epoch= 300 current loss= 0.12542152404785156\n",
      "epoch= 400 current loss= 0.060367897152900696\n",
      "epoch= 500 current loss= 0.02905631624162197\n",
      "epoch= 600 current loss= 0.013985454104840755\n",
      "epoch= 700 current loss= 0.006731476169079542\n",
      "epoch= 800 current loss= 0.003239987650886178\n",
      "epoch= 900 current loss= 0.0015594608848914504\n",
      "epoch= 1000 current loss= 0.0007506075198762119\n",
      "epoch= 1100 current loss= 0.00036127775092609227\n",
      "epoch= 1200 current loss= 0.0001738895516609773\n",
      "epoch= 1300 current loss= 8.369737770408392e-05\n",
      "epoch= 1400 current loss= 4.028180774184875e-05\n",
      "epoch= 1500 current loss= 1.9388991859159432e-05\n",
      "epoch= 1600 current loss= 9.332107765658293e-06\n",
      "epoch= 1700 current loss= 4.49232129540178e-06\n",
      "epoch= 1800 current loss= 2.1626240140903974e-06\n",
      "epoch= 1900 current loss= 1.0411837365609244e-06\n",
      "epoch= 2000 current loss= 5.01161991905974e-07\n"
     ]
    }
   ],
   "source": [
    "# 반복적인 학습을 진행, for문을 통해 학습 중간 과정을 출력\n",
    "nums_epochs =2000\n",
    "\n",
    "for epoch in range(nums_epochs+1):\n",
    "\n",
    "    prediction=model(x_train) #모델에 데이터를 전달하면 model class의 forward()함수가 자동으로 진행\n",
    "    loss=loss_function(prediction,y_train) #피드포워드 계산 값과 정답값의 오차를 계산\n",
    "\n",
    "    #역전파 코드 \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch%100==0:\n",
    "        loss_val=loss.item()\n",
    "        print('epoch=',epoch,'current loss=',loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "309e5036-8d22-40a8-86d4-49f8731d59e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1028],\n",
       "        [-1.0027],\n",
       "        [ 3.1988],\n",
       "        [-0.5025]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test=torch.Tensor([-3.1,-3.0,1.2,-2.5]).view(4,1)\n",
    "\n",
    "pred=model(x_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaea973d-1e49-4009-bf53-d72ab43c8512",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
